{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2006f5db-934a-43ec-89a5-375e31e4e7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.measure import regionprops\n",
    "\n",
    "def mask_cartridge_case(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the image to grayscale for better processing\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply GaussianBlur to reduce noise and improve contour detection\n",
    "    blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "\n",
    "    # Apply the Canny edge detection algorithm\n",
    "    edges = cv2.Canny(blurred_image, 100, 200)\n",
    "\n",
    "    # Morphological operations to clean up the edge map\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "    closed = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n",
    "    opened = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Apply erosion to the edge map to remove small edges\n",
    "    erosion = cv2.erode(opened, kernel, iterations=1)\n",
    "\n",
    "    # Apply dilation to the eroded edge map to restore the edges that were removed\n",
    "    dilation = cv2.dilate(erosion, kernel, iterations=1)\n",
    "\n",
    "    # Find contours in the edge map\n",
    "    contours, _ = cv2.findContours(dilation, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Initialize lists to store the bounding boxes of the contours\n",
    "    breech_face_contours = []\n",
    "    aperture_shear_contours = []\n",
    "    firing_pin_contours = []\n",
    "\n",
    "    # Iterate through the contours and extract the bounding boxes\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if w > h:  # Breech-face impression is typically wider than it is tall\n",
    "            breech_face_contours.append((x, y, w, h))\n",
    "        elif w < h and w/h > 0.5:  # Aperture shear is typically taller than it is wide and has an aspect ratio greater than 0.5\n",
    "            aperture_shear_contours.append((x, y, w, h))\n",
    "        elif w == h:  # Firing pin impression is typically square\n",
    "            firing_pin_contours.append((x, y, w, h))\n",
    "\n",
    "    # Extract the regions of interest (ROIs) from the image using the bounding boxes\n",
    "    if breech_face_contours:\n",
    "        breech_face_roi = image[min(breech_face_contours)[1]:max(breech_face_contours)[1]+max(breech_face_contours)[3],\n",
    "                                min(breech_face_contours)[0]:max(breech_face_contours)[0]+max(breech_face_contours)[2]]\n",
    "\n",
    "    if aperture_shear_contours:\n",
    "        aperture_shear_roi = image[min(aperture_shear_contours)[1]:max(aperture_shear_contours)[1]+max(aperture_shear_contours)[3],\n",
    "                                   min(aperture_shear_contours)[0]:max(aperture_shear_contours)[0]+max(aperture_shear_contours)[2]]\n",
    "\n",
    "    if firing_pin_contours:\n",
    "        firing_pin_roi = image[min(firing_pin_contours)[1]:max(firing_pin_contours)[1]+max(firing_pin_contours)[3],\n",
    "                               min(firing_pin_contours)[0]:max(firing_pin_contours)[0]+max(firing_pin_contours)[2]]\n",
    "\n",
    "    # Convert the ROIs to grayscale and apply thresholding\n",
    "    gray_breech_face = cv2.cvtColor(breech_face_roi, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary_breech_face = cv2.threshold(gray_breech_face, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    gray_aperture_shear = cv2.cvtColor(aperture_shear_roi, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary_aperture_shear = cv2.threshold(gray_aperture_shear, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    gray_firing_pin = cv2.cvtColor(firing_pin_roi, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary_firing_pin = cv2.threshold(gray_firing_pin, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Calculate the moments of the binary images\n",
    "    props_breech_face = regionprops(binary_breech_face)\n",
    "    props_aperture_shear = regionprops(binary_aperture_shear)\n",
    "    props_firing_pin = regionprops(binary_firing_pin)\n",
    "\n",
    "    # Calculate the orientation of the ROIs\n",
    "    breech_face_orientation = props_breech_face[0].orientation\n",
    "    aperture_shear_orientation = props_aperture_shear[0].orientation\n",
    "    firing_pin_orientation = props_firing_pin[0].orientation\n",
    "\n",
    "    # Calculate the direction of the firing pin drag\n",
    "    firing_pin_drag_direction = aperture_shear_orientation - firing_pin_orientation\n",
    "\n",
    "    # Analyze the shape and size of the ROIs\n",
    "    breech_face_perimeter = props_breech_face[0].perimeter\n",
    "    breech_face_aspect_ratio = props_breech_face[0].minor_axis_length / props_breech_face[0].major_axis_length\n",
    "    breech_face_circularity = (4 * np.pi * props_breech_face[0].area) / (breech_face_perimeter ** 2)\n",
    "\n",
    "    aperture_shear_perimeter = props_aperture_shear[0].perimeter\n",
    "    aperture_shear_aspect_ratio = props_aperture_shear[0].minor_axis_length / props_aperture_shear[0].major_axis_length\n",
    "    aperture_shear_circularity = (4 * np.pi * props_aperture_shear[0].area) / (aperture_shear_perimeter ** 2)\n",
    "\n",
    "    firing_pin_perimeter = props_firing_pin[0].perimeter\n",
    "    firing_pin_aspect_ratio = props_firing_pin[0].minor_axis_length / props_firing_pin[0].major_axis_length\n",
    "    firing_pin_circularity = (4 * np.pi * props_firing_pin[0].area) / (firing_pin_perimeter ** 2)\n",
    "\n",
    "    # Initialize masks with the shape of the image\n",
    "    breech_face_mask = np.zeros_like(image)\n",
    "    aperture_shear_mask = np.zeros_like(image)\n",
    "    firing_pin_mask = np.zeros_like(image)\n",
    "\n",
    "    # Convert bounding boxes to contours\n",
    "    breech_face_contours = [np.array([[x, y], [x + w, y], [x + w, y + h], [x, y + h]]) for x, y, w, h in breech_face_contours]\n",
    "    aperture_shear_contours = [np.array([[x, y], [x + w, y], [x + w, y + h], [x, y + h]]) for x, y, w, h in aperture_shear_contours]\n",
    "    firing_pin_contours = [np.array([[x, y], [x + w, y], [x + w, y + h], [x, y + h]]) for x, y, w, h in firing_pin_contours]\n",
    "\n",
    "    # Draw contours on masks\n",
    "    if breech_face_contours:\n",
    "        cv2.drawContours(breech_face_mask, breech_face_contours, -1, (255, 0, 0), -1)\n",
    "\n",
    "    if aperture_shear_contours:\n",
    "        cv2.drawContours(aperture_shear_mask, aperture_shear_contours, -1, (0, 255, 0), -1)\n",
    "\n",
    "    if firing_pin_contours:\n",
    "        cv2.drawContours(firing_pin_mask, firing_pin_contours, -1, (128, 0, 128), -1)\n",
    "\n",
    "    # Combine masks\n",
    "    combined_mask = breech_face_mask + aperture_shear_mask + firing_pin_mask\n",
    "\n",
    "    # Convert combined_mask to a single-channel (grayscale) mask\n",
    "    combined_mask_gray = cv2.cvtColor(combined_mask, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply the combined mask to the original image\n",
    "    result_image = cv2.bitwise_and(image, image, mask=combined_mask_gray)\n",
    "\n",
    "    # Add an arrow indicating the direction of firing pin drag\n",
    "    arrow_length = 50\n",
    "    arrow_angle = 30\n",
    "    arrow_tip = (int(image.shape[1] / 2), int(image.shape[0] / 2))\n",
    "    arrow_end = (\n",
    "        int(arrow_tip[0] + arrow_length * np.cos(np.radians(arrow_angle))),\n",
    "        int(arrow_tip[1] - arrow_length * np.sin(np.radians(arrow_angle)))\n",
    "    )\n",
    "    cv2.arrowedLine(result_image, arrow_tip, arrow_end, (255, 0, 0), thickness=2)  # Blue arrow\n",
    "\n",
    "    # Display the original image and the masked result\n",
    "    cv2.imshow('Original Image', image)\n",
    "    cv2.imshow('Masked Result', result_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "image_path = \"image_0.jpg\"\n",
    "mask_cartridge_case(image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475f88d7-487e-4558-89eb-c3d5293559a0",
   "metadata": {},
   "source": [
    "Here I have used a single image for example because there was no dataset available on cartridge cases. And I didn't create a dataset because the images availble on internet were of varied quality (size, pixels etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4634c3f1-3678-4f4c-b4d3-a98b9a6761c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
